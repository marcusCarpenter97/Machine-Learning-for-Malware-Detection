
from dataset import Dataset
from decisionTreeClassifier import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix


def run_benchmarks(size_of_training_set, number_of_runs):
      results = []
      for run in range(number_of_runs):
            training_data, testing_data, training_labels, testing_labels = data.partition_data(size_of_training_set)
            results.append(tree_classifier.benchmark_tree_classifier(training_data, testing_data,
                                                                     training_labels, testing_labels))

      for index, result in enumerate(results):
            print(f"--------Benchmark---{index}-----------------\n"
                  f"Time taken to train model: {result[0]}\nTime taken to predict new data: {result[1]}\n"
                  f"Time taken to calculate accuracy: {result[2]}")


# Prepare data
data = Dataset()
data.load_data()

tree_classifier = DecisionTreeClassifier()

run_benchmarks(0.33, 10)

"""
training_data, testing_data, training_labels, testing_labels = data.partition_data(0.33)

# Create model
tree_classifier = DecisionTreeClassifier()
tree_classifier.train_model(training_data, training_labels)

# Predict
tree_classifier.predict(testing_data)
tree_classifier.calculate_accuracy(testing_data, testing_labels)

# Create pdf of decision tree
tree_classifier.export_tree_as_pdf(data.feature_names, data.label_names)

print(f"Accuracy: {tree_classifier.accuracy}")

tree_classifier.print_confusion_matrix(testing_labels)
"""