
import pytest
from dataset import Dataset

dataset = Dataset()


@pytest.fixture(autouse=True)
def clean_up():
    dataset = Dataset()


def test_load_dataset_valid_input_and_adjust_data_true():
    dataset.load_data(0.3)
    # Fail if not loaded properly
    if not (dataset.features and dataset.labels and dataset.feature_names):
        pytest.fail()


def test_load_dataset_invalid_malware_rate():
    # Causes Type error in adjust_data method
    dataset.load_data("invalid")


def test_load_dataset_invalid_adjust_data():
    # Python defaults to default value
    dataset.load_data(0.3, "invalid")


def test_load_dataset_adjust_data_false():
    dataset.load_data(0.3, False)


def test_partition_data():
    malware_rate = 0.3
    train_set_size = 0.2

    dataset.load_data(malware_rate)
    train_d, test_d, train_l, test_l = dataset.partition_data(train_set_size)

    total_size_of_dataset = len(train_d) + len(test_d)

    rate = len(test_d) / total_size_of_dataset

    # If the size of the test set does not fit the ratio then fail the test
    if not round(rate, 1) == train_set_size:
        pytest.fail()


def test_adjust_data():
    # load with adjust option
    # count malware and benign
    # check if it matches input
    adjust_option = 0.1
    dataset.load_data(0.1)

    benign_count = 0
    malware_count = 0

    for label in dataset.labels:
        if label == "Malware":
            malware_count += 1
        else:
            benign_count += 1

    rate = malware_count / len(dataset.labels)
    # Fail if rate does not match input
    if not round(rate, 1) == adjust_option:
        pytest.fail()


def test_clear_dataset():
    dataset.load_data(0.3)
    if dataset.features and dataset.labels and dataset.feature_names:
        dataset.clear_dataset()
        if (dataset.features or dataset.labels or dataset.feature_names):
            # Fail if not deleted properly 
            pytest.fail()
    else:  # Fail if not loaded properly 
        pytest.fail()


def test_load_mist_data():
    pytest.fail()


def test_load_unique():
    # Load data
    # Split
    # Load unique
    # Check if is unique
    dataset.load_data(0.3)
    train_d, test_d, train_l, test_l = dataset.partition_data(0.3)
    dataset.load_unique(train_d, train_l, 0.3)

    for item in dataset.features:
        # If a repeat is found then the test fails.
        if item in train_d:
            pytest.fail()

